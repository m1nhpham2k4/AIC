{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:06.359801Z",
     "iopub.status.busy": "2025-08-08T11:27:06.359513Z",
     "iopub.status.idle": "2025-08-08T11:27:13.447083Z",
     "shell.execute_reply": "2025-08-08T11:27:13.446260Z",
     "shell.execute_reply.started": "2025-08-08T11:27:06.359782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in d:\\summer_2025\\aic\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (0.22.1)\n",
      "Requirement already satisfied: opencv-python-headless in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (4.11.0.86)\n",
      "Requirement already satisfied: scipy in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (1.16.0)\n",
      "Requirement already satisfied: numpy in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (11.3.0)\n",
      "Requirement already satisfied: scikit-image in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: filelock in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from torch->easyocr) (80.9.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from scikit-image->easyocr) (2025.6.11)\n",
      "Requirement already satisfied: packaging>=21 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from scikit-image->easyocr) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\summer_2025\\aic\\venv\\lib\\site-packages (from jinja2->torch->easyocr) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:13.449179Z",
     "iopub.status.busy": "2025-08-08T11:27:13.448907Z",
     "iopub.status.idle": "2025-08-08T11:27:15.321993Z",
     "shell.execute_reply": "2025-08-08T11:27:15.321268Z",
     "shell.execute_reply.started": "2025-08-08T11:27:13.449154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"d:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measyocr\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\easyocr\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01measyocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Reader\n\u001b[32m      3\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m1.7.2\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\easyocr\\easyocr.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_recognizer, get_text\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m group_text_box, get_image_list, calculate_md5, get_paragraph,\\\n\u001b[32m      5\u001b[39m                    download_and_unzip, printProgressBar, diff, reformat_input,\\\n\u001b[32m      6\u001b[39m                    make_rotated_img_list, set_result_with_confidence,\\\n\u001b[32m      7\u001b[39m                    reformat_input_batched, merge_to_free\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\easyocr\\recognition.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcudnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcudnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\torch\\__init__.py:270\u001b[39m\n\u001b[32m    266\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    268\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in path/nvidia/lib_folder/lib or path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\torch\\__init__.py:253\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    249\u001b[39m     err = ctypes.WinError(last_error)\n\u001b[32m    250\u001b[39m     err.strerror += (\n\u001b[32m    251\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    252\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    255\u001b[39m     is_loaded = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [WinError 127] The specified procedure could not be found. Error loading \"d:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:15.323106Z",
     "iopub.status.busy": "2025-08-08T11:27:15.322757Z",
     "iopub.status.idle": "2025-08-08T11:27:15.363729Z",
     "shell.execute_reply": "2025-08-08T11:27:15.363183Z",
     "shell.execute_reply.started": "2025-08-08T11:27:15.323087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keyframes_dir = 'Keyframes_test'\n",
    "all_keyframe_paths = dict()\n",
    "for part in sorted(os.listdir(keyframes_dir)):\n",
    "    # data_part = part.split('_')[-1]\n",
    "    parts = part.split('_')\n",
    "    data_part = parts[-2] + \"_\" + parts[-1] if len(parts) == 3 else parts[-1]\n",
    "    \n",
    "    all_keyframe_paths[data_part] =  dict()\n",
    "    data_part_path = f'{keyframes_dir}/Keyframes_{data_part}/keyframes'\n",
    "    frame_dirs = sorted(os.listdir(data_part_path))\n",
    "    frame_ids = [frame_dir.split('_')[-1] for frame_dir in frame_dirs]\n",
    "    for frame_id, frame_dir in zip(frame_ids, frame_dirs):\n",
    "        keyframe_paths = sorted(glob.glob(f'{data_part_path}/{frame_dir}/*.jpg'))\n",
    "\n",
    "        all_keyframe_paths[data_part][frame_id] =  keyframe_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:15.365660Z",
     "iopub.status.busy": "2025-08-08T11:27:15.365050Z",
     "iopub.status.idle": "2025-08-08T11:27:15.370750Z",
     "shell.execute_reply": "2025-08-08T11:27:15.370010Z",
     "shell.execute_reply.started": "2025-08-08T11:27:15.365633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['L01', 'L02', 'L03', 'L04', 'L05'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keyframe_paths.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:15.371699Z",
     "iopub.status.busy": "2025-08-08T11:27:15.371480Z",
     "iopub.status.idle": "2025-08-08T11:27:15.380646Z",
     "shell.execute_reply": "2025-08-08T11:27:15.379999Z",
     "shell.execute_reply.started": "2025-08-08T11:27:15.371683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keys = list(all_keyframe_paths.keys())\n",
    "# midpoint = len(keys) // 2\n",
    "# sub_dict_1 = {key: all_keyframe_paths[key] for key in keys[:midpoint]}\n",
    "# sub_dict_2 = {key: all_keyframe_paths[key] for key in keys[midpoint:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T11:27:19.109192Z",
     "iopub.status.busy": "2025-08-08T11:27:19.108884Z",
     "iopub.status.idle": "2025-08-08T11:27:23.742550Z",
     "shell.execute_reply": "2025-08-08T11:27:23.741880Z",
     "shell.execute_reply.started": "2025-08-08T11:27:19.109171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'easyocr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reader = \u001b[43measyocr\u001b[49m.Reader([\u001b[33m'\u001b[39m\u001b[33mvi\u001b[39m\u001b[33m'\u001b[39m], gpu=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# this needs to run only once to load the model into memory\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'easyocr' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir = 'Keyframes_test/ocr_results'\n",
    "ocr = PaddleOCR(use_textline_orientation=True, lang='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-08T11:27:28.760Z",
     "iopub.execute_input": "2025-08-08T11:27:26.281102Z",
     "iopub.status.busy": "2025-08-08T11:27:26.280140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÅ Processing dataset parts:   0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20156\\4273571219.py:14: DeprecationWarning: Please use `predict` instead.\n",
      "  result = ocr.ocr(image_path)\n",
      "üìº L01:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [1:23:14<2:04:51, 2497.04s/it]\n",
      "üìÅ Processing dataset parts:   0%|          | 0/5 [1:23:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m video_ocr_results = []\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m keyframe_paths:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     result = \u001b[43mocr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     all_texts = []\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\typing_extensions.py:2956\u001b[39m, in \u001b[36mdeprecated.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2953\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(arg)\n\u001b[32m   2954\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m   2955\u001b[39m     warnings.warn(msg, category=category, stacklevel=stacklevel + \u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddleocr\\_pipelines\\ocr.py:225\u001b[39m, in \u001b[36mPaddleOCR.ocr\u001b[39m\u001b[34m(self, img, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease use `predict` instead.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mocr\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddleocr\\_pipelines\\ocr.py:208\u001b[39m, in \u001b[36mPaddleOCR.predict\u001b[39m\u001b[34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    196\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     text_rec_score_thresh=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    207\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_textline_orientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_textline_orientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_det_limit_side_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_det_limit_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_det_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_det_box_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_det_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_rec_score_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.predict\u001b[39m\u001b[34m(self, input, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executor.execute(\n\u001b[32m    124\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    125\u001b[39m         *args,\n\u001b[32m    126\u001b[39m         **kwargs,\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pipeline.predict(\n\u001b[32m    130\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    131\u001b[39m         *args,\n\u001b[32m    132\u001b[39m         **kwargs,\n\u001b[32m    133\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\pipelines\\ocr\\pipeline.py:400\u001b[39m, in \u001b[36m_OCRPipeline.predict\u001b[39m\u001b[34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_max_side_limit, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_rec_score_thresh)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# use textline orientation model\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_settings[\u001b[33m\"\u001b[39m\u001b[33muse_textline_orientation\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    398\u001b[39m     angles = \u001b[43m[\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtextline_angle_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtextline_angle_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtextline_orientation_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mall_subs_of_imgs\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    404\u001b[39m     all_subs_of_imgs = \u001b[38;5;28mself\u001b[39m.rotate_image(all_subs_of_imgs, angles)\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:211\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, input, batch_size, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m output[\u001b[32m0\u001b[39m]\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:267\u001b[39m, in \u001b[36mBasePredictor.apply\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    265\u001b[39m     batches = \u001b[38;5;28mself\u001b[39m.batch_sampler(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m     prediction = PredictionWrap(prediction, \u001b[38;5;28mlen\u001b[39m(batch_data))\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_data)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\models\\image_classification\\predictor.py:105\u001b[39m, in \u001b[36mClasPredictor.process\u001b[39m\u001b[34m(self, batch_data, topk)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m, batch_data: List[Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray]], topk: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     94\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     95\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    Process a batch of data through the preprocessing, inference, and postprocessing.\u001b[39;00m\n\u001b[32m     97\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        dict: A dictionary containing the input path, raw image, class IDs, scores, and label names for every instance of the batch. Keys include 'input_path', 'input_img', 'class_ids', 'scores', and 'label_names'.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     batch_raw_imgs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocessors\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRead\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     batch_imgs = \u001b[38;5;28mself\u001b[39m.preprocessors[\u001b[33m\"\u001b[39m\u001b[33mResize\u001b[39m\u001b[33m\"\u001b[39m](imgs=batch_raw_imgs)\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCrop\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.preprocessors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\common\\reader\\image_reader.py:49\u001b[39m, in \u001b[36mReadImage.__call__\u001b[39m\u001b[34m(self, imgs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"apply\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\paddlex\\inference\\common\\reader\\image_reader.py:54\u001b[39m, in \u001b[36mReadImage.read\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, np.ndarray):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format == \u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bs = 16\n",
    "save_dir = '/kaggle/working/ocr'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "keys = sorted(all_keyframe_paths.keys())\n",
    "for key in tqdm(keys):\n",
    "    video_keyframe_paths = all_keyframe_paths[key]\n",
    "    video_ids = sorted(video_keyframe_paths.keys())\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_dir, key)):\n",
    "        os.mkdir(os.path.join(save_dir, key))\n",
    "\n",
    "    for video_id in tqdm(video_ids):\n",
    "        video_keyframe_path = video_keyframe_paths[video_id]\n",
    "        video_ocr_results = []\n",
    "        video_ocr_results_path = []\n",
    "        for i in range(0, len(video_keyframe_path), bs):\n",
    "            # Support batchsize inferencing\n",
    "            image_paths = video_keyframe_path[i:i+bs]\n",
    "\n",
    "            results = reader.readtext_batched(image_paths, batch_size=len(image_paths))\n",
    "            for result in results:\n",
    "                refined_result = []\n",
    "                for item in result: \n",
    "                    if item[2] > 0.5:\n",
    "                        refined_result.append(item)   \n",
    "                refined_result = easyocr.utils.get_paragraph(refined_result)\n",
    "                text_detected = [item[1] for item in refined_result]\n",
    "                video_ocr_results.append(text_detected)\n",
    "                video_ocr_results_path.append(image_paths)\n",
    "\n",
    "        with open(f'{save_dir}/{key}/{video_id}.json',\"w\", encoding='utf-8') as jsonfile:\n",
    "            json.dump(video_ocr_results, jsonfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8032664,
     "sourceId": 12709522,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
