{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1b558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Summer_2025\\AIC\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Chọn model mạnh hơn: ViT-g-14 (huấn luyện trên LAION-2B)cái \n",
    "model_name = \"ViT-SO400M-16-SigLIP2-384\"\n",
    "pretrained = \"webli\"\n",
    "\n",
    "# Load model + preprocess\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=model_name,\n",
    "    pretrained=pretrained,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load tokenizer cho text\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f8f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    image_input = preprocess(image).to(device).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "    \n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return image_features.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5984a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_pil(img_like):\n",
    "    if isinstance(img_like, str):\n",
    "        with Image.open(img_like) as im:\n",
    "            return im.convert(\"RGB\").copy()\n",
    "    elif isinstance(img_like, Image.Image):\n",
    "        return img_like.convert(\"RGB\").copy()\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported type for image: {type(img_like)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cu chay file quẻy trước di\n",
    "vang anh\n",
    "anh nghi? ngoi di a. Em ngoi lam lai anh ôi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6c0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embed(text: str):\n",
    "\n",
    "    ###### TEXT FEATURES EXTRACTING ######\n",
    "    text = tokenizer([text]).to(device)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features.cpu().detach().numpy()\n",
    "\n",
    "    return text_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640fff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def embed_images(images):\n",
    "    # pil_img = _to_pil(images)\n",
    "    batch = torch.stack([preprocess(img) for img in images]).to(device)\n",
    "    feats = model.encode_image(batch).float()\n",
    "    return feats.cpu().numpy().astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ca56ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img = r'D:\\Summer_2025\\AIC\\Data_extraction\\Keyframes_2025\\Keyframes_L21\\keyframes\\L21_V001\\005.jpg'\n",
    "imgs = Image.open(file_img).convert(\"RGB\").copy()\n",
    "test_img = embed_images([imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666a7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'a man sitting on a motorbike' # query voi text nay , chay ben file query cuxng duoc\n",
    "# oke anh, de em ngoi lam anh a.\n",
    "te = text_embed(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "146042aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1152)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916a7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file = r'D:\\Summer_2025\\AIC\\Data_extraction\\features\\L21_V001.npy'\n",
    "a = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3cf8e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.006508,  0.0324  ,  0.00977 , ...,  0.005356, -0.0218  ,\n",
       "        0.0423  ], dtype=float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b3605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 1152)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f705abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "dim = a.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(a)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8667e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1da1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00650787,  0.03240967,  0.00977325, ...,  0.00535583,\n",
       "       -0.02180481,  0.04229736], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "364fae38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43fa3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(te, k=3) # neeus tra ve `38` laf ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2fd203c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11039707, 0.10580194, 0.10005827]], dtype=float32),\n",
       " array([[ 38, 165, 168]], dtype=int64))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D,I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b90127",
   "metadata": {},
   "outputs": [],
   "source": [
    "gio em check code cac phan lien quan toi embed_text been file query.py cua em nha \n",
    "\n",
    "copy khong sua logic , chay dung cau query anh de do, ra kq giong la ok\n",
    "ok anh\n",
    "ma tai sao lai. la` 38 v anh\n",
    "\n",
    "gio chay query.py \n",
    "sao cho array tra ve 38 ha? anh\n",
    "dung roi , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ed517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = faiss.read_index(INDEX_PATH)\n",
    "# # tăng recall nếu cần\n",
    "# faiss.ParameterSpace().set_index_parameter(index, \"nprobe\", 256)\n",
    "import ujson\n",
    "conn = sqlite3.connect(SQLITE_DB)\n",
    "\n",
    "def search_vec(vec, k=10):\n",
    "    D, I = index.search(vec, k)\n",
    "    out = []\n",
    "    for s, idx in zip(D[0].tolist(), I[0].tolist()):\n",
    "        if idx == -1: continue\n",
    "        row = conn.execute(\"SELECT path, payload FROM docs WHERE id=?\", (int(idx),)).fetchone()\n",
    "        if row:\n",
    "            out.append({\"id\": int(idx), \"score\": float(s), \"path\": row[0], \"payload\": ujson.loads(row[1])})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4649c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX_LEN = int(model.text.positional_embedding.shape[0])\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    try:\n",
    "        toks = open_clip.tokenize(texts, context_length=CTX_LEN, truncate=True)\n",
    "    except TypeError:\n",
    "        # Fallback cho bản open-clip cũ không có 'truncate'\n",
    "        toks = open_clip.tokenize(texts, context_length=CTX_LEN)\n",
    "        # đảm bảo đúng [B, CTX_LEN]\n",
    "        if toks.shape[1] > CTX_LEN:\n",
    "            toks = toks[:, :CTX_LEN]\n",
    "        elif toks.shape[1] < CTX_LEN:\n",
    "            pad = torch.zeros((toks.shape[0], CTX_LEN - toks.shape[1]), dtype=toks.dtype)\n",
    "            toks = torch.cat([toks, pad], dim=1)\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6c43a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      2\u001b[39m USE_COSINE = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_text\u001b[39m(texts):\n\u001b[32m      5\u001b[39m     toks = tokenizer(texts).to(device)\n\u001b[32m      6\u001b[39m     feats = model.encode_text(toks).float()\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "USE_COSINE = False\n",
    "@torch.no_grad()\n",
    "def embed_text(texts):\n",
    "    toks = tokenizer(texts).to(device)\n",
    "    feats = model.encode_text(toks).float()\n",
    "    if USE_COSINE:\n",
    "        feats = F.normalize(feats, dim=-1)\n",
    "    return feats.cpu().numpy().astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ebec5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = 'a man sitting on a motorbike'\n",
    "te_test = embed_text(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b082f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1152)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7a3faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(te_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab547af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11039121, 0.10579748, 0.10005896]], dtype=float32),\n",
       " array([[ 38, 165, 168]], dtype=int64))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D,I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca2eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
